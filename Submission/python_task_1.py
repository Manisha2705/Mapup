# -*- coding: utf-8 -*-
"""Python_task_1.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L_iQdrbrtKbSmLoNmnAKKAQYS_wP6wgx
"""

#Python_task_1 Solution-1
import pandas as pd

def generate_car_matrix(dataset):
    # Read the CSV file into a DataFrame
    df = pd.read_csv(dataset)

    # Pivot the DataFrame to create the desired matrix
    result_df = df.pivot(index='id_1', columns='id_2', values='car').fillna(0)

    # Set diagonal values to 0
    for col in result_df.columns:
        result_df.at[col, col] = 0

    return result_df

# Example usage
dataset_path = '/content/dataset-1.csv'
result_dataframe = generate_car_matrix(dataset_path)
print(result_dataframe)

#Python_task_1 Solution-2
import pandas as pd

def get_type_count(dataset):
    # Read the CSV file into a DataFrame
    df = pd.read_csv(dataset)

    # Add a new categorical column 'car_type'
    df['car_type'] = pd.cut(df['car'], bins=[float('-inf'), 15, 25, float('inf')],
                            labels=['low', 'medium', 'high'], right=False)

    # Calculate the count of occurrences for each car_type category
    type_counts = df['car_type'].value_counts().to_dict()

    # Sort the dictionary alphabetically based on keys
    sorted_type_counts = dict(sorted(type_counts.items()))

    return sorted_type_counts

# Example usage
dataset_path = '/content/dataset-1.csv'
result = get_type_count(dataset_path)
print(result)

#Python_task_1 Solution-3
import pandas as pd

def get_bus_indexes(dataset):
    # Read the CSV file into a DataFrame
    df = pd.read_csv(dataset)

    # Calculate the mean value of the 'bus' column
    mean_bus_value = df['bus'].mean()

    # Identify indices where 'bus' values are greater than twice the mean value
    bus_indexes = df[df['bus'] > 2 * mean_bus_value].index.tolist()

    # Sort the indices in ascending order
    bus_indexes.sort()

    return bus_indexes

# Example usage
dataset_path = '/content/dataset-1.csv'
result = get_bus_indexes(dataset_path)
print(result)

#Python_task_1 Solution-4
import pandas as pd

def filter_routes(dataset):
    # Read the CSV file into a DataFrame
    df = pd.read_csv(dataset)

    # Filter routes based on the average of the 'truck' column
    filtered_routes = df.groupby('route')['truck'].mean()
    filtered_routes = filtered_routes[filtered_routes > 7].index.tolist()

    # Sort the list of routes in ascending order
    filtered_routes.sort()

    return filtered_routes

# Example usage
dataset_path = '/content/dataset-1.csv'
result = filter_routes(dataset_path)
print(result)

#Python_task_1 Solution-5
import pandas as pd

def multiply_matrix(input_df):
    # Copy the DataFrame to avoid modifying the original
    modified_df = input_df.copy()

    # Apply the specified logic to each value in the DataFrame
    modified_df = modified_df.applymap(lambda x: x * 0.75 if x > 20 else x * 1.25)

    # Round values to 1 decimal place
    modified_df = modified_df.round(1)

    return modified_df

# Example usage
result_dataframe = pd.DataFrame(result_dataframe)
modified_result = multiply_matrix(result_dataframe)
print(modified_result)

#python_task_1 soluthion -6
import pandas as pd

def check_timestamp_completeness(df):
    # Combine date and time columns into a single timestamp column with a specified format
    df['start_timestamp'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'], format='%d-%m-%y %H:%M:%S', errors='coerce')
    df['end_timestamp'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'], format='%d-%m-%y %H:%M:%S', errors='coerce')

    # Check if the time duration for each (id, id_2) pair covers a full 24-hour period
    df['time_coverage'] = (df['end_timestamp'] - df['start_timestamp']).dt.total_seconds() == 24 * 60 * 60

    # Extract day of the week from the start timestamps
    df['day_of_week'] = df['start_timestamp'].dt.day_name()

    # Check if timestamps span all 7 days of the week
    day_of_week_set = set(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])
    df['day_coverage'] = df.groupby(['id', 'id_2'])['day_of_week'].transform(lambda x: set(x) == day_of_week_set)

    # Create a boolean series indicating completeness for each (id, id_2) pair
    boolean_series = df.groupby(['id', 'id_2']).apply(lambda x: all(x['time_coverage']) and all(x['day_coverage'])).astype(bool)

    return boolean_series

# Load the CSV file into a DataFrame
file_path = '/content/dataset-2.csv'  # Replace this with your file path
dataset = pd.read_csv(file_path)

# Call the function and get the boolean series
boolean_result = check_timestamp_completeness(dataset)
print(boolean_result)